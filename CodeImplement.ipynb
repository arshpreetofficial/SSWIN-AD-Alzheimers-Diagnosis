{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SSWIN-AD Alzheimer's Disease Classification**\n",
        "- Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
        "- Spectral Swin Transformer (SSWIN)\n",
        "- Adaptive Contrast-aware Fine-Tuning (ACaFT)\n",
        "- CNN Ensemble (AlexNet, GoogLeNet, ResNet-18)"
      ],
      "metadata": {
        "id": "bY-_XxGLQHOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "rcNTkLg6QBVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KIxC5VUGPdCJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "XEiWAdtpSv6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 4\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "7YG82w0MSs6c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLAHE Implementation"
      ],
      "metadata": {
        "id": "Iv2pdbWuQAzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CLAHETransform:\n",
        "    def __init__(self, clipLimit=2.0, tileGridSize=(8,8)):\n",
        "        self.clipLimit = clipLimit\n",
        "        self.tileGridSize = tileGridSize\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=self.clipLimit, tileGridSize=self.tileGridSize)\n",
        "        l = clahe.apply(l)\n",
        "        lab = cv2.merge((l, a, b))\n",
        "        return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)"
      ],
      "metadata": {
        "id": "QOXsoqRwQRSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "k55zUFgJQV8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    CLAHETransform(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder('datasets/train', transform=transform)\n",
        "test_dataset = datasets.ImageFolder('datasets/test', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "F5bZhmwYRF_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spectral Swin Transformer Implementation"
      ],
      "metadata": {
        "id": "cQ_ohHgOTVlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralSwinTransformer(nn.Module):\n",
        "    def __init__(self, embed_dim=96, num_classes=4):\n",
        "        super(SpectralSwinTransformer, self).__init__()\n",
        "        self.transformer = models.swin_v2_t(weights='DEFAULT')\n",
        "        self.fc = nn.Linear(1000, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.transform_to_spectral(x)\n",
        "        x = self.model(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "    def transform_to_spectral(self, x):\n",
        "        x_fft = torch.fft.fft2(x)\n",
        "        x_fft_shifted = torch.fft.fftshift(x_fft)\n",
        "        magnitude_spectrum = torch.abs(x_fft)\n",
        "        return magnitude_spectrum\n",
        "\n",
        "sswin_model = SpectralSwinTransformer()"
      ],
      "metadata": {
        "id": "LhkGqpgvTXJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model Initialization"
      ],
      "metadata": {
        "id": "jSYzHMi-TbmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n",
        "googlenet = models.googlenet(pretrained=True)\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, num_classes)\n",
        "googlenet.fc = nn.Linear(googlenet.fc.in_features, num_classes)\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
        "\n",
        "models_list = [alexnet, googlenet, resnet18]"
      ],
      "metadata": {
        "id": "JadF9-ipTfNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaptive Contrast-aware Fine-Tuning (ACaFT)"
      ],
      "metadata": {
        "id": "rKIkyNeOTkaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acaft_fine_tune(model, loader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, momentum=0.9)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for images, labels in loader:\n",
        "            spectral_features = spectral_swin_transformer(images)\n",
        "            outputs = model(spectral_features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(loader):.4f}\")"
      ],
      "metadata": {
        "id": "l04n4UW1TnNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune Models"
      ],
      "metadata": {
        "id": "O6QYCa_vTq9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in [alexnet, googlenet, resnet18]:\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in list(model.parameters())[-10:]:\n",
        "        param.requires_grad = True\n",
        "    acaft_fine_tune(model, train_loader)"
      ],
      "metadata": {
        "id": "29avjBBeTuAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Evaluation"
      ],
      "metadata": {
        "id": "XKNIjUniTwvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_preds, ensemble_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        spectral_features = spectral_swin_transformer(images)\n",
        "        outputs = [torch.softmax(model(spectral_features), dim=1) for model in [alexnet, googlenet, resnet18]]\n",
        "        ensemble_output = torch.mean(torch.stack(outputs), dim=0)\n",
        "        pred_labels = torch.argmax(ensemble_output, dim=1)\n",
        "\n",
        "        ensemble_preds.extend(pred_labels.cpu().numpy())\n",
        "        ensemble_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "LpbBvu08TzlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Metrics"
      ],
      "metadata": {
        "id": "HzyP71JYT32n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(ensemble_labels, ensemble_preds)\n",
        "precision = precision_score(ensemble_labels, ensemble_preds, average='weighted')\n",
        "recall = recall_score(ensemble_labels, ensemble_preds, average='weighted')\n",
        "f1 = f1_score(ensemble_labels, ensemble_preds, average='weighted')\n",
        "\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision * 100:.2f}%\")\n",
        "print(f\"Recall: {recall * 100:.2f}%\")\n",
        "print(f\"F1 Score: {f1 * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "yzM5TjTtT8yW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}